{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"VandB_TweetList.txt\"\n",
    "Key = 'wjQqcP8hTwOUBHBca7Ens3cZH'\n",
    "Secret = 'c6ZNbGfoo4cW0Sy0MgoerWMeaKa9wdH7O1zjljx4MKN6i3onvu'\n",
    "search_words = ['#Baroda','#Vadodara','#SmartCitiesIndia']\n",
    "search_terms = ['Traffic',\n",
    "'Transport',\n",
    "'Mobility',\n",
    "'Cycle',\n",
    "'Congestion',\n",
    "'Parking',\n",
    "'\\\"Private Vehicles\\\"',\n",
    "'Pollution',\n",
    "'\\\"Multi Modal\\\"',\n",
    "'E-Rickshaw',\n",
    "'Roads',\n",
    "'Bus',\n",
    "'Flyover',\n",
    "'\\\"Smart Cities\\\"',\n",
    "'Bike',\n",
    "'Car',\n",
    "'Road',\n",
    "'Walk',\n",
    "'Footpath',\n",
    "'Pedestrian',\n",
    "'Rickshaw',\n",
    "'Electric',\n",
    "'Signal',\n",
    "'Highway']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import tweepy as tw\n",
    "import matplotlib.pyplot as plot\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "\n",
    "\n",
    "Tweets_dict = dict()\n",
    "auth = tw.OAuthHandler(Key, Secret)\n",
    "api = tw.API(auth)\n",
    "terms_grouped = []\n",
    "\n",
    "while True:\n",
    "    with open(file,\"r\") as f:\n",
    "        Tweets_dict = json.load(f)\n",
    "        \n",
    "    for i in range(0,len(search_terms),4):\n",
    "        group = search_terms[i:i+4]\n",
    "        query_string = \" OR \".join(search_words)+\" \"+\" OR \".join(group)+' -filter:retweets'\n",
    "        try: \n",
    "            tweets = tw.Cursor(api.search, q=query_string, lang='en').items()\n",
    "            for tweet in tweets:\n",
    "                text = re.sub(r'https:\\/\\/t.co\\S{1,11}', '', tweet.text, flags=re.MULTILINE)\n",
    "                Tweets_dict[tweet.id] = text\n",
    "                print(text)\n",
    "        except tw.TweepError:\n",
    "            print(\"Error : too many requests\")\n",
    "        time.sleep(40)\n",
    "    time.sleep(30)\n",
    "\n",
    "    with open(file,\"w\") as f:\n",
    "        f.write(json.dumps(Tweets_dict,ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
